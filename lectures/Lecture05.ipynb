{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Newton's method is important\n",
    "\n",
    "We've discussed two methods for solving $f(x) = 0$:\n",
    "\n",
    "1. The bisection method.\n",
    "2. Fixed-point iteration applied to $g(x) = x-f(x)$.\n",
    "\n",
    "Method 1 is guaranteed to work. \n",
    "\n",
    "Method 2 is simpler (and can converge faster if $\\text{|slope|} < \\frac{1}{2}$) but it can fail (when |slope| $> 1$).  \n",
    "\n",
    "We now give yet another method that is more robust than method 2 (but still not as robust as method 1) and converges faster than both methods. The method is called __Newton's method__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation for Newton's Method \n",
    "\n",
    "We are trying to find $p$ such that $f(p) = 0$.   Assume $f \\in C^2[a,b]$ and that $p^*$ is close to $p$.  We use Taylor's theorem to find that for some $\\xi(p^*)$\n",
    "\n",
    "$$ f(p) = f(p^*) + f'(p^*)(p-p^*) + \\frac{f''(\\xi(p^*))}{2} (p-p^*)^2. $$\n",
    "\n",
    "Neglecting the correction term, and using $f(p) = 0$, we get:\n",
    "\n",
    "$$ 0 \\approx f(p^*) + f'(p^*)(p-p^*)$$ \n",
    "\n",
    "or \n",
    "\n",
    "$$ p \\approx p ^* -\\frac{f(p^*)}{f'(p^*)}$$\n",
    "\n",
    "This last relation gives the Newton iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithm for Newton's method\n",
    "\n",
    "Given an initial guess $p_0\\in [a,b]$ for a root of $f(x) \\in C[a,b]$, the __Newton iteration__ is given by\n",
    "\n",
    "$$ p_n = p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{n-1})}.$$\n",
    "\n",
    "## Geometric interpretation \n",
    "\n",
    "Newton iteration first approximates $f(x)$ by its tangent line approximation at $x = p_{n-1}$, given by\n",
    "\n",
    "$$ f(x) \\approx L(x) = f(p_{n-1}) + f'(p_{n-1})(x - p_{n-1}). $$\n",
    "\n",
    "Then to approximate a root of $f(x)$, the $x$-intercept of the tangent line is computed $L(p_n) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance of the Newton method \n",
    "\n",
    "Suppose we want to address how well Newton does at solving\n",
    "\n",
    "$$ f(x) = x - \\cos x = 0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use 10 iterations of the fixed-point method to get a good approximation of the root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "g = lambda x: np.cos(x) # g(x) = x - f(x)\n",
    "\n",
    "p_initial = 0.2 # initial guess\n",
    "p = p_initial\n",
    "for i in range(10):\n",
    "    p = g(p)\n",
    "p_exact = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For Newton, we must manually compute $f'(x) = 1 + \\sin(x)$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "f = lambda x: x - np.cos(x)\n",
    "df = lambda x: 1 + np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison of Newton's method with fixed-point iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How well does fixed-point iteration do after 2 iterations? ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from fixed-point iteration =  0.175010172449\n"
     ]
    }
   ],
   "source": [
    "p = p_initial\n",
    "p = g(p)\n",
    "p = g(p)\n",
    "print 'Error from fixed-point iteration = ', abs(p - p_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How well does Newton iteration do after 2 iterations? ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from Newton iteration =  0.00955276821107\n"
     ]
    }
   ],
   "source": [
    "p = p_initial\n",
    "p = p - f(p)/df(p)\n",
    "p = p - f(p)/df(p)\n",
    "print 'Error from Newton iteration = ', abs(p - p_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence of Newton's method\n",
    "\n",
    "#### Theorem\n",
    "\n",
    "Let $f \\in C^2[a,b]$.  If $p \\in [a,b]$ is such that $f(p) = 0$ and $f'(p) \\neq 0$, then there exists $\\delta > 0$ such that Newton's method generates a sequence $\\{p_n\\}_{n=1}^\\infty$  that converges to $p$ if $p_0 \\in [p-\\delta, p + \\delta]$.\n",
    "\n",
    "#### Proof\n",
    "\n",
    "Note that $p$ is a fixed point of $\\displaystyle g(x) = x - \\frac{f(x)}{f'(x)}$. \n",
    "\n",
    "Therefore, we must use the hypotheses of the theorem to show $g(x)$ satisfies the convergence criteria for fixed-point iteration.  This is not trivial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Proposition\n",
    "\n",
    "Suppose $g \\in C^1[a,b]$ and $g(p) = p$ for $p \\in (a,b)$.  Assume further that $|g'(p)| = P < 1$.  Then there exists $\\delta > 0$, such that \n",
    "\n",
    "(1) $|g'(x)| \\leq K < 1$ for $x \\in [p-\\delta, p+\\delta]$ and \n",
    "\n",
    "(2) $g(x) \\in [p-\\delta,p + \\delta]$ \n",
    "\n",
    "\n",
    "#### Proof\n",
    "\n",
    "(1) Because $|g'(x)|$ is continuous: For $\\epsilon = (1-P)/2$ there exists $\\delta> 0$ such that \n",
    "\n",
    "$$||g'(x)| - P| \\leq \\epsilon  \\text{  for  } |x-p|\\leq \\delta.$$  \n",
    "\n",
    "Thus for $x \\in [p-\\delta,p+\\delta]$, \n",
    "\n",
    "$$P - (1-P)/2 \\leq |g'(x)| \\leq P + (1-P)/2,$$\n",
    "\n",
    "or \n",
    "\n",
    "$$|g'(x)| \\leq P  + (1-P)/2 = (1+P)/2 < 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(2) Use Taylor's theorem which states for some $\\xi(p)$\n",
    "\n",
    "$$ g(x) = g(p) + g'(\\xi(p))(x-p).$$\n",
    "\n",
    "Rearranging,\n",
    "\n",
    "$$ |g(x)-g(p)| = |g'(\\xi(p)| |x-p| \\leq |x-p| < \\delta, ~\\text{ for }~ |x-p| \\leq \\delta. $$\n",
    "\n",
    "Since $g(p) = p$, for $x \\in [p-\\delta,p+\\delta]$ we have $|g(x) - p| < \\delta$ or $g(x) \\in [p-\\delta,p+\\delta]$.\n",
    "\n",
    "This completes the proof of the proposition\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And so, to prove convergence of Newton's method we need to show that the function\n",
    "\n",
    "$$g(x) = x - f(x)/f'(x)$$\n",
    "\n",
    "has a derivative that is less than 1 at $x = p$.   Indeed,\n",
    "\n",
    "$$g'(x) = 1 - \\frac{[f'(x)]^2 - f(x)f''(x)}{[f'(x)]^2} = \\frac{f(x)f''(x)}{[f'(x)]^2}.$$\n",
    "\n",
    "Since $f(p) = 0$, $g'(p) = 0$, which is less than 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A complication of Newton's method that often comes up in practice is that you need to know how to compute $f'(x)$. This can be impractical in some cases and tedious in others.  The __secant method__ and the __method of false position__ are modifications of Newton's method that remedy this.  We will not focus too much attention on these other methods.\n",
    "\n",
    "Newton's method also has a generalization to higher dimensions to solve, for example, $f(x,y) = 0$.  Then the division by $f'(p_n)$ is replaced by the inversion of the Jacobian.  We will discuss this later in the course if time permits."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
